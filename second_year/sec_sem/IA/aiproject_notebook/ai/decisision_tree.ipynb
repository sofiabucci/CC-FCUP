{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações necessárias\n",
    "from typing import Union\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from pandas import DataFrame, Series, read_csv\n",
    "from game import rules as game        # Importa regras do jogo Connect4\n",
    "from game import constants as c       \n",
    "from joblib import load, dump         # Para salvar e carregar modelos com persistência\n",
    "\n",
    "\n",
    "# Classe que representa um nó da árvore de decisão\n",
    "class DTNode:\n",
    "    def __init__(self, feature_index=None, feature_name=None, children=None, info_gain=None, split_values=None, leaf_value=None) -> None:\n",
    "        self.feature_index = feature_index      # Índice do atributo usado para o split\n",
    "        self.feature_name = feature_name        # Nome do atributo\n",
    "        self.children = children                # Dicionário de nós filhos\n",
    "        self.info_gain = info_gain              # Ganho de informação do split\n",
    "        self.split_values = split_values        # Valores do atributo para cada ramo\n",
    "        self.leaf_value = leaf_value            # Valor da classe se o nó for uma folha\n",
    "\n",
    "# Classe que constrói e faz previsões com árvore de decisão\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth: int = None, min_samples_split: int = None, criterium: str = 'entropy') -> None:\n",
    "        self.root = None                        # Nó raiz da árvore\n",
    "        self.max_depth = max_depth              # Profundidade máxima permitida\n",
    "        self.min_samples_split = min_samples_split  # Número mínimo de amostras para dividir\n",
    "        self.criterium = criterium              # Critério de impureza (gini ou entropia)\n",
    "\n",
    "    # Treinamento da árvore\n",
    "    def fit(self, X_train: DataFrame, y_train: Series) -> None:\n",
    "        dataset = pd.concat((X_train, y_train), axis=1)  # Une dados e rótulos\n",
    "        self.root = self._build_tree(dataset)            # Constrói a árvore recursivamente\n",
    "\n",
    "    # Constrói a árvore de forma recursiva\n",
    "    def _build_tree(self, dataset: DataFrame, curr_depth: int = 0) -> DTNode:\n",
    "        X_train = dataset.iloc[:, :-1]\n",
    "        y_train = dataset.iloc[:, -1]\n",
    "        num_samples, num_features = X_train.shape\n",
    "\n",
    "        # Condições de parada da recursão (puro, profundidade, amostras mínimas)\n",
    "        if num_samples >= self.min_samples_split and curr_depth <= self.max_depth and not self._is_pure(y_train):\n",
    "            best_split = self._get_best_split(dataset)\n",
    "            if best_split[\"info_gain\"] > 0:\n",
    "                children = {\n",
    "                    feature_value: self._build_tree(subset, curr_depth + 1)\n",
    "                    for feature_value, subset in best_split[\"splits\"].items()\n",
    "                }\n",
    "                return DTNode(best_split[\"feature_index\"], best_split[\"feature_name\"], children, best_split[\"info_gain\"], best_split[\"splits\"].keys())\n",
    "\n",
    "        # Caso base: retorna um nó folha com o valor mais comum\n",
    "        leaf_value = self._calculate_leaf_value(y_train)\n",
    "        return DTNode(leaf_value=leaf_value)\n",
    "\n",
    "    # Retorna o valor mais comum (modo) para usar como folha\n",
    "    def _calculate_leaf_value(self, y_train: Series) -> any:\n",
    "        y_train = list(y_train)\n",
    "        return max(y_train, key=y_train.count)\n",
    "\n",
    "    # Verifica se todos os valores da coluna são iguais\n",
    "    def _is_pure(self, target_column: Series) -> bool:\n",
    "        return len(set(target_column)) == 1\n",
    "\n",
    "    # Encontra o melhor atributo e divisão dos dados\n",
    "    def _get_best_split(self, dataset: DataFrame) -> dict:\n",
    "        best_split = {}\n",
    "        max_info_gain = -float(\"inf\")\n",
    "        num_features = dataset.shape[1] - 1\n",
    "\n",
    "        for feature_index in range(num_features):\n",
    "            feature_name = dataset.columns[feature_index]\n",
    "            feature_values = dataset.iloc[:, feature_index]\n",
    "            splits = self._discrete_split(dataset, feature_index)\n",
    "\n",
    "            # Calcula o ganho de informação da divisão\n",
    "            info_gain = self._discrete_info_gain(dataset.iloc[:, -1], splits)\n",
    "\n",
    "            # Atualiza se for o melhor ganho encontrado\n",
    "            if info_gain > max_info_gain:\n",
    "                best_split = self._update_best_split(feature_index, feature_name, info_gain, splits)\n",
    "                max_info_gain = info_gain\n",
    "\n",
    "        return best_split\n",
    "\n",
    "    # Atualiza o dicionário com as melhores informações de split\n",
    "    def _update_best_split(self, feature_index, feature_name, info_gain, splits) -> dict:\n",
    "        return {\n",
    "            \"feature_index\": feature_index,\n",
    "            \"feature_name\": feature_name,\n",
    "            \"info_gain\": info_gain,\n",
    "            \"splits\": splits,\n",
    "        }\n",
    "\n",
    "    # Realiza split discreto dos dados por valor da feature\n",
    "    def _discrete_split(self, dataset: DataFrame, feature_index: int) -> dict:\n",
    "        splits = {}\n",
    "        for feature_value in dataset.iloc[:, feature_index].unique():\n",
    "            splits[feature_value] = dataset[dataset.iloc[:, feature_index] == feature_value]\n",
    "        return splits\n",
    "\n",
    "    # Calcula o ganho de informação com base nos splits\n",
    "    def _discrete_info_gain(self, y_train: Series, splits: dict) -> float:\n",
    "        weight_average = sum((len(subset) / len(y_train)) * self._get_impurity(subset.iloc[:, -1]) for subset in splits.values())\n",
    "        return self._get_impurity(y_train) - weight_average\n",
    "\n",
    "    # Retorna a impureza segundo o critério escolhido\n",
    "    def _get_impurity(self, y_train: Series) -> float:\n",
    "        return self._entropy(y_train) if self.criterium == \"entropy\" else self._gini_index(y_train)\n",
    "\n",
    "    # Cálculo da entropia\n",
    "    def _entropy(self, y_train: Series) -> float:\n",
    "        class_labels = list(set(y_train))\n",
    "        probabilities = [y_train.tolist().count(label) / len(y_train) for label in class_labels]\n",
    "        return -sum(p * np.log2(p) for p in probabilities if p > 0)\n",
    "\n",
    "    # Cálculo do índice de Gini\n",
    "    def _gini_index(self, y_train: Series) -> float:\n",
    "        class_labels = list(set(y_train))\n",
    "        probabilities = [y_train.tolist().count(label) / len(y_train) for label in class_labels]\n",
    "        return 1 - sum(p ** 2 for p in probabilities)\n",
    "\n",
    "    # Previsões para um DataFrame de dados\n",
    "    def predict(self, X_test: DataFrame) -> list:\n",
    "        return [self.make_prediction(row, self.root) for _, row in X_test.iterrows()]\n",
    "\n",
    "    # Faz a previsão para uma única amostra\n",
    "    def make_prediction(self, row: tuple, node: DTNode) -> Union[any, None]:\n",
    "        while node and node.leaf_value is None:\n",
    "            value = row[node.feature_index]\n",
    "            if value in node.children:\n",
    "                node = node.children[value]\n",
    "            else:\n",
    "                return None  # Valor não esperado na árvore\n",
    "        return node.leaf_value\n",
    "\n",
    "# Classe que encapsula o uso da árvore para diferentes domínios\n",
    "class DecisionTree:\n",
    "    def __init__(self, mode='iris'):\n",
    "        self.mode = mode  # Modo: 'iris' ou 'connect4'\n",
    "        self.clf = None   # Classificador\n",
    "        self.initialize_model()\n",
    "\n",
    "    # Inicializa o modelo conforme o modo\n",
    "    def initialize_model(self):\n",
    "        if self.mode == 'iris':\n",
    "            self._initialize_iris_model()\n",
    "        elif self.mode == 'connect4':\n",
    "            self._initialize_connect4_model()\n",
    "\n",
    "    # Inicializa modelo para o dataset Iris\n",
    "    def _initialize_iris_model(self):\n",
    "        try:\n",
    "            self.clf = load(\"model/iris_model.joblib\")\n",
    "        except FileNotFoundError:\n",
    "            df = read_csv(\"model/iris.csv\")\n",
    "            X = df.iloc[:, :-1]\n",
    "            y = df.iloc[:, -1]\n",
    "            self.clf = DecisionTreeClassifier(3, 2, \"entropy\")\n",
    "            self.clf.fit(X, y)\n",
    "            dump(self.clf, \"model/iris_model.joblib\")\n",
    "\n",
    "    # Inicializa modelo para o jogo Connect4\n",
    "    def _initialize_connect4_model(self):\n",
    "        try:\n",
    "            self.clf = load(\"model/connect4_model.joblib\")\n",
    "        except FileNotFoundError:\n",
    "            df = read_csv(\"model/connect4.csv\")\n",
    "            X = df.iloc[:, :-1]\n",
    "            y = df.iloc[:, -1]\n",
    "            self.clf = DecisionTreeClassifier(5, 2, \"entropy\")\n",
    "            self.clf.fit(X, y)\n",
    "            dump(self.clf, \"model/connect4_model.joblib\")\n",
    "\n",
    "    # Faz a previsão para os dados da íris\n",
    "    def predict_iris(self, sepal_length, sepal_width, petal_length, petal_width):\n",
    "        X_test = pd.DataFrame([[sepal_length, sepal_width, petal_length, petal_width]])\n",
    "        return self.clf.predict(X_test)[0]\n",
    "\n",
    "    # Decide a melhor jogada para o jogo Connect4\n",
    "    def play(self, board):\n",
    "        possible_plays = game.get_possible_plays(board)\n",
    "        possible_states = []\n",
    "        for play in possible_plays:\n",
    "            new_board = game.make_play(play, c.PLAYER1, board)\n",
    "            possible_states.append((play, new_board))\n",
    "\n",
    "        board_dicts = [game.to_dict(board) for _, board in possible_states]\n",
    "        df = pd.DataFrame(board_dicts)\n",
    "        predictions = self.clf.predict(df)\n",
    "\n",
    "        # Cria um dicionário de colunas por previsão\n",
    "        prediction_dict = {}\n",
    "        for i, prediction in enumerate(predictions):\n",
    "            if prediction not in prediction_dict:\n",
    "                prediction_dict[prediction] = []\n",
    "            prediction_dict[prediction].append(possible_states[i][0])\n",
    "\n",
    "        # Prioriza vitória, depois empate, depois evitar derrota\n",
    "        if c.WIN in prediction_dict:\n",
    "            return random.choice(prediction_dict[c.WIN])\n",
    "        elif c.DRAW in prediction_dict:\n",
    "            return random.choice(prediction_dict[c.DRAW])\n",
    "        elif c.LOSS in prediction_dict:\n",
    "            return random.choice(prediction_dict[c.LOSS])\n",
    "        else:\n",
    "            return random.choice(possible_plays)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
